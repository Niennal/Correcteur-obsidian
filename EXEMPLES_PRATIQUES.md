# Exemples pratiques - Comprendre par la pratique

Ce guide compl√®te FONCTIONNEMENT_TECHNIQUE.md avec des exemples concrets et des cas d'usage r√©els.

## Table des mati√®res

1. [Exemple complet: Correction d'une note](#exemple-complet-correction-dune-note)
2. [Exemple: Cr√©er un outil personnalis√©](#exemple-cr√©er-un-outil-personnalis√©)
3. [Exemple: Modifier le comportement du correcteur](#exemple-modifier-le-comportement-du-correcteur)
4. [Exemple: Workflow automatis√©](#exemple-workflow-automatis√©)
5. [Debugging et troubleshooting](#debugging-et-troubleshooting)

---

## Exemple complet: Correction d'une note

### Sc√©nario r√©el

Vous avez une note `Projets/rapport.md` avec ce contenu:

```markdown
# Rapport du projet

Aujourdhui jai travailler sur le projet. Voici les taches accomplies:

- Corriger les bug
- Ameliorer la performance
- Tester le systeme

Les resultat sont encourageant!
```

### √âtape par √©tape du processus

#### 1. Lancement du script

```bash
source venv/bin/activate
python correct_spelling.py
```

**Ce qui se passe en m√©moire:**

```python
# Python charge le script
import os
import sys
from dotenv import load_dotenv
# ...

# Charge les variables .env
load_dotenv()
# ‚Üí Lit .env
# ‚Üí Met OBSIDIAN_VAULT_PATH dans os.environ

VAULT_PATH = os.getenv("OBSIDIAN_VAULT_PATH")
# ‚Üí VAULT_PATH = "/Users/moi/vault"
```

#### 2. Initialisation du correcteur

```python
corrector = SpellingCorrector(
    vault_path="/Users/moi/vault",
    model="llama3.1:8b"
)
```

**En m√©moire:**

```
Heap Python:
‚îú‚îÄ SpellingCorrector instance
‚îÇ  ‚îú‚îÄ vault_path: Path("/Users/moi/vault")
‚îÇ  ‚îú‚îÄ tools: ObsidianTools instance
‚îÇ  ‚îÇ  ‚îî‚îÄ vault_path: Path("/Users/moi/vault")
‚îÇ  ‚îî‚îÄ llm: Ollama instance
‚îÇ     ‚îú‚îÄ model: "llama3.1:8b"
‚îÇ     ‚îú‚îÄ base_url: "http://localhost:11434"
‚îÇ     ‚îî‚îÄ temperature: 0.1
```

#### 3. Menu utilisateur

```
Votre choix: 2
Chemin de la note: Projets/rapport.md
```

**Code ex√©cut√©:**

```python
choice = input("Votre choix: ").strip()  # "2"

if choice == "2":
    note_path = input("Chemin de la note: ").strip()  # "Projets/rapport.md"
    result = corrector.correct_note(note_path)
```

#### 4. Lecture de la note

```python
def correct_note(self, note_path: str):
    full_path = self.vault_path / note_path
    # full_path = Path("/Users/moi/vault/Projets/rapport.md")

    with open(full_path, 'r', encoding='utf-8') as f:
        original_content = f.read()
```

**Contenu en m√©moire:**

```python
original_content = """# Rapport du projet

Aujourdhui jai travailler sur le projet. Voici les taches accomplies:

- Corriger les bug
- Ameliorer la performance
- Tester le systeme

Les resultat sont encourageant!"""
```

**Taille en m√©moire:** ~200 bytes (texte ASCII/UTF-8)

#### 5. Cr√©ation du backup

```python
backup_path = self.create_backup(full_path)
```

**Op√©rations filesystem:**

```
1. datetime.now() ‚Üí "2025-11-30 15:30:45"
2. strftime("%Y%m%d_%H%M%S") ‚Üí "20251130_153045"
3. backup_path = "/Users/moi/vault/.backups/rapport_20251130_153045.md"
4. shutil.copy2(original, backup)
   ‚Üí Copie fichier avec m√©tadonn√©es
```

**V√©rification:**

```bash
ls -la /Users/moi/vault/.backups/
# -rw-r--r--  rapport_20251130_153045.md
```

#### 6. Correction via LLM

```python
corrected_content = self.correct_text(original_content)
```

**Construction du prompt:**

```python
prompt = f"""Tu es un correcteur orthographique expert en fran√ßais.

R√àGLES IMPORTANTES:
1. Corrige UNIQUEMENT les fautes d'orthographe, de grammaire et de ponctuation
2. Ne modifie PAS la structure Markdown (titres ##, listes -, liens [[]], tags #)
...

TEXTE √Ä CORRIGER:
# Rapport du projet

Aujourdhui jai travailler sur le projet. Voici les taches accomplies:
...

TEXTE CORRIG√â:"""
```

**Longueur du prompt:** ~500 caract√®res = ~125 tokens

**Appel HTTP √† Ollama:**

```python
# Langchain fait en arri√®re-plan:
import requests

response = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "llama3.1:8b",
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.1,
            "num_predict": 1024
        }
    }
)

# R√©ponse d'Ollama (simplifi√©):
{
    "model": "llama3.1:8b",
    "created_at": "2025-11-30T15:30:50Z",
    "response": "# Rapport du projet\n\nAujourd'hui j'ai travaill√©...",
    "done": true,
    "total_duration": 2500000000,  # 2.5 secondes en nanosecondes
    "load_duration": 100000000,     # 0.1 seconde (d√©j√† charg√©)
    "prompt_eval_count": 125,       # 125 tokens dans le prompt
    "eval_count": 85                # 85 tokens g√©n√©r√©s
}
```

**Processus dans Ollama:**

```
1. Ollama re√ßoit requ√™te HTTP
   ‚Üì
2. Mod√®le llama3.1:8b d√©j√† en RAM? Oui (charg√© au premier appel)
   ‚Üì
3. Tokenize le prompt: "Tu es un correcteur..." ‚Üí [tokens]
   ‚Üì
4. Passe les tokens au mod√®le neural
   ‚Üì
5. Mod√®le g√©n√®re token par token:
   "Aujourd" ‚Üí "'" ‚Üí "hui" ‚Üí " " ‚Üí "j" ‚Üí "'" ‚Üí "ai" ‚Üí " " ‚Üí "travaill√©" ...
   ‚Üì
6. Arr√™t quand:
   - G√©n√®re token de fin </s>
   - OU atteint num_predict (1024 tokens)
   ‚Üì
7. Retourne le texte complet
```

**RAM utilis√©e pendant la correction:**

```
Ollama server:
‚îú‚îÄ llama3.1:8b model: 4.7 GB
‚îú‚îÄ Prompt context: 125 tokens √ó 4 bytes = 500 bytes
‚îú‚îÄ Generation buffer: 85 tokens √ó 4 bytes = 340 bytes
‚îî‚îÄ Total: ~4.7 GB

Python script:
‚îú‚îÄ Original content: 200 bytes
‚îú‚îÄ Corrected content: 220 bytes
‚îú‚îÄ Prompt string: 500 bytes
‚îî‚îÄ Total: ~1 KB (n√©gligeable)
```

**R√©sultat retourn√©:**

```python
corrected_content = """# Rapport du projet

Aujourd'hui j'ai travaill√© sur le projet. Voici les t√¢ches accomplies:

- Corriger les bugs
- Am√©liorer la performance
- Tester le syst√®me

Les r√©sultats sont encourageants!"""
```

#### 7. Comparaison et d√©cision

```python
if corrected_content == original_content:
    return {"success": True, "changes": False}
```

**Comparaison en Python:**

```python
# Python compare caract√®re par caract√®re
original_content[0:10]  = "# Rapport "
corrected_content[0:10] = "# Rapport "
# ‚úì Identiques

original_content[30:40] = "Aujourdhui"
corrected_content[30:40] = "Aujourd'hu"
# ‚úó Diff√©rents ‚Üí changes = True
```

#### 8. √âcriture du fichier corrig√©

```python
with open(full_path, 'w', encoding='utf-8') as f:
    f.write(corrected_content)
```

**Op√©rations filesystem:**

```
1. Ouvre /Users/moi/vault/Projets/rapport.md en mode 'w'
   ‚Üí Tronque le fichier (vide tout)
2. √âcrit corrected_content
   ‚Üí Encode UTF-8: "Aujourd'hui" ‚Üí bytes
3. Ferme le fichier
   ‚Üí Flush buffer vers disque
```

**V√©rification:**

```bash
cat /Users/moi/vault/Projets/rapport.md
# Rapport du projet
#
# Aujourd'hui j'ai travaill√© sur le projet...
```

#### 9. Retour du r√©sultat

```python
return {
    "success": True,
    "changes": True,
    "backup": "/Users/moi/vault/.backups/rapport_20251130_153045.md"
}
```

**Affichage √† l'utilisateur:**

```
‚úÖ Note corrig√©e: Projets/rapport.md
üíæ Backup: .backups/rapport_20251130_153045.md
```

### Timeline compl√®te

```
T+0ms    : Utilisateur lance script
T+100ms  : Python charge modules
T+200ms  : Charge .env
T+300ms  : Initialise SpellingCorrector
T+400ms  : Affiche menu
T+5000ms : Utilisateur entre choix
T+5100ms : Lit fichier rapport.md (200 bytes)
T+5120ms : Cr√©e backup
T+5150ms : Construit prompt
T+5200ms : Envoie requ√™te HTTP √† Ollama
T+5250ms : Ollama re√ßoit requ√™te
T+5300ms : Tokenize prompt (125 tokens)
T+5400ms : Commence g√©n√©ration
T+7400ms : G√©n√©ration termin√©e (85 tokens, ~2 secondes)
T+7450ms : Retourne r√©sultat
T+7500ms : Compare original vs corrig√©
T+7520ms : √âcrit fichier
T+7550ms : Affiche r√©sultat √† l'utilisateur

Total: ~7.5 secondes
```

---

## Exemple: Cr√©er un outil personnalis√©

### Besoin: Extraire tous les tags d'une note

```python
# Ajouter dans obsidian_tools.py

def extract_tags(self, note_path: str) -> str:
    """
    Extrait tous les tags (#tag) d'une note.

    Args:
        note_path: Chemin relatif de la note

    Returns:
        Liste des tags trouv√©s
    """
    full_path = self.vault_path / note_path

    if not full_path.exists():
        return f"Erreur: Note introuvable"

    # Lire le contenu
    content = full_path.read_text(encoding='utf-8')

    # Extraire les tags avec regex
    import re
    # Pattern: # suivi de lettres/chiffres/- mais pas d'espace
    pattern = r'#([a-zA-Z0-9_-]+)'
    tags = re.findall(pattern, content)

    # D√©dupliquer (enlever doublons)
    unique_tags = sorted(set(tags))

    if not unique_tags:
        return f"Aucun tag trouv√© dans {note_path}"

    return f"Tags dans {note_path}:\n" + "\n".join(f"  - #{tag}" for tag in unique_tags)
```

**Utilisation:**

```python
tools = ObsidianTools("/vault")
result = tools.extract_tags("Projets/rapport.md")
print(result)

# Output:
# Tags dans Projets/rapport.md:
#   - #important
#   - #projet
#   - #urgent
```

**Comment fonctionne la regex:**

```python
pattern = r'#([a-zA-Z0-9_-]+)'

D√©composition:
- r'...'           : Raw string (pas d'√©chappement \)
- #                : Caract√®re # litt√©ral
- (...)            : Groupe de capture
- [a-zA-Z0-9_-]    : Un caract√®re alphanum√©rique ou _ ou -
- +                : Un ou plusieurs

Exemples:
"Voici #projet et #urgent-2025"
         ^^^^^^     ^^^^^^^^^^^
         Groupe 1   Groupe 2

re.findall() retourne: ['projet', 'urgent-2025']
```

### Besoin: Compter les mots dans une note

```python
def count_words(self, note_path: str) -> str:
    """Compte les mots dans une note."""
    full_path = self.vault_path / note_path

    if not full_path.exists():
        return f"Erreur: Note introuvable"

    content = full_path.read_text(encoding='utf-8')

    # Supprimer le code (entre ```)
    import re
    content_no_code = re.sub(r'```.*?```', '', content, flags=re.DOTALL)

    # Supprimer les titres Markdown (##)
    content_no_headers = re.sub(r'^#+\s+', '', content_no_code, flags=re.MULTILINE)

    # Compter les mots
    words = content_no_headers.split()
    word_count = len(words)

    # Compter les caract√®res (sans espaces)
    char_count = len(content_no_headers.replace(' ', '').replace('\n', ''))

    # Estimer temps de lecture (250 mots/minute)
    reading_time = round(word_count / 250, 1)

    return f"""Statistiques pour {note_path}:
  Mots: {word_count}
  Caract√®res: {char_count}
  Temps de lecture: ~{reading_time} min"""
```

**Flags regex expliqu√©s:**

```python
re.DOTALL
# . match aussi les \n (par d√©faut . ne match pas \n)

re.MULTILINE
# ^ et $ matchent d√©but/fin de ligne (pas juste d√©but/fin de texte)

re.sub(r'```.*?```', '', content, flags=re.DOTALL)
#        ^^^
#        .*?  = non-greedy (s'arr√™te au premier ```)
#        .*   = greedy (irait jusqu'au dernier ```)

Exemple:
content = "Texte ```code1``` autre ```code2``` fin"

Avec .*? (non-greedy):
Supprime: ```code1``` et ```code2```
R√©sultat: "Texte  autre  fin"

Avec .* (greedy):
Supprime: ```code1``` autre ```code2```
R√©sultat: "Texte  fin"
```

---

## Exemple: Modifier le comportement du correcteur

### Cas 1: Corriger seulement certains types de fautes

```python
# Dans correct_spelling.py, m√©thode correct_text()

def correct_text_grammar_only(self, text: str) -> str:
    """Corrige uniquement la grammaire, pas l'orthographe."""

    prompt = f"""Tu es un correcteur grammatical expert en fran√ßais.

R√àGLES STRICTES:
1. Corrige UNIQUEMENT les erreurs de grammaire et d'accord
2. NE corrige PAS l'orthographe des mots individuels
3. Corrige les accords (genre, nombre, temps)
4. Corrige les conjugaisons
5. Ne modifie PAS la structure Markdown
6. Retourne UNIQUEMENT le texte corrig√©

Exemples:
- "Les chiens mange" ‚Üí "Les chiens mangent" (accord)
- "Il a manger" ‚Üí "Il a mang√©" (participe pass√©)
- "ortographe" ‚Üí "ortographe" (NE CHANGE PAS l'orthographe!)

TEXTE √Ä CORRIGER:
{text}

TEXTE CORRIG√â:"""

    return self.llm.invoke(prompt).strip()
```

**Diff√©rence avec correction compl√®te:**

```python
# Correction compl√®te
Entr√©e:  "Les chiens mange des gateau"
Sortie:  "Les chiens mangent des g√¢teaux"
         ^^^^^^^^        ^^^^^^^^^^^^^^
         Accord          Accord + orthographe

# Correction grammaire seulement
Entr√©e:  "Les chiens mange des gateau"
Sortie:  "Les chiens mangent des gateau"
         ^^^^^^^^        ^^^^^^^
         Accord          Orthographe inchang√©e
```

### Cas 2: Correction en plusieurs passes

```python
def correct_text_multiple_passes(self, text: str) -> str:
    """
    Corrige en plusieurs passes pour meilleure qualit√©.

    Pass 1: Orthographe
    Pass 2: Grammaire
    Pass 3: Ponctuation
    """

    # Pass 1: Orthographe
    prompt1 = f"""Corrige UNIQUEMENT l'orthographe des mots.
Ne touche PAS √† la grammaire ou la ponctuation.

TEXTE: {text}
CORRIG√â:"""

    text_pass1 = self.llm.invoke(prompt1).strip()

    # Pass 2: Grammaire
    prompt2 = f"""Corrige UNIQUEMENT les accords et la grammaire.
L'orthographe est d√©j√† correcte.

TEXTE: {text_pass1}
CORRIG√â:"""

    text_pass2 = self.llm.invoke(prompt2).strip()

    # Pass 3: Ponctuation
    prompt3 = f"""Corrige UNIQUEMENT la ponctuation.
Tout le reste est d√©j√† correct.

TEXTE: {text_pass2}
CORRIG√â:"""

    text_pass3 = self.llm.invoke(prompt3).strip()

    return text_pass3
```

**Avantages:**
- Plus de pr√©cision (focus sur un aspect √† la fois)
- Le mod√®le fait moins d'erreurs

**Inconv√©nients:**
- 3√ó plus lent (3 appels LLM)
- 3√ó plus de RAM/CPU

**Quand l'utiliser:**
- Documents importants (articles, th√®ses)
- Quand la qualit√© prime sur la vitesse

### Cas 3: Correction avec v√©rification

```python
def correct_text_with_verification(self, text: str) -> str:
    """Corrige et v√©rifie que le Markdown est pr√©serv√©."""

    # Extraire structure Markdown avant correction
    import re

    # Trouver tous les titres
    headers_before = re.findall(r'^#+\s+.+$', text, re.MULTILINE)

    # Trouver tous les liens
    links_before = re.findall(r'\[\[.+?\]\]', text)

    # Trouver tous les tags
    tags_before = re.findall(r'#[a-zA-Z0-9_-]+', text)

    # Corriger
    corrected = self.correct_text(text)

    # V√©rifier structure apr√®s correction
    headers_after = re.findall(r'^#+\s+.+$', corrected, re.MULTILINE)
    links_after = re.findall(r'\[\[.+?\]\]', corrected)
    tags_after = re.findall(r'#[a-zA-Z0-9_-]+', corrected)

    # Comparer
    if len(headers_before) != len(headers_after):
        print(f"‚ö†Ô∏è ATTENTION: Nombre de titres chang√©!")
        print(f"   Avant: {len(headers_before)}, Apr√®s: {len(headers_after)}")

    if set(links_before) != set(links_after):
        print(f"‚ö†Ô∏è ATTENTION: Liens modifi√©s!")
        print(f"   Supprim√©s: {set(links_before) - set(links_after)}")
        print(f"   Ajout√©s: {set(links_after) - set(links_before)}")

    if set(tags_before) != set(tags_after):
        print(f"‚ö†Ô∏è ATTENTION: Tags modifi√©s!")

    return corrected
```

---

## Exemple: Workflow automatis√©

### Script: Correction quotidienne automatique

```python
#!/usr/bin/env python3
"""
daily_correction.py - Corrige automatiquement les notes Daily
"""
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv
from correct_spelling import SpellingCorrector

def correct_daily_notes():
    """Corrige les notes quotidiennes de la semaine."""

    load_dotenv()
    vault_path = os.getenv("OBSIDIAN_VAULT_PATH")

    corrector = SpellingCorrector(vault_path, model="llama3.1:8b")

    # Obtenir les 7 derniers jours
    today = datetime.now()
    dates = [(today - timedelta(days=i)).strftime("%Y-%m-%d") for i in range(7)]

    print("üóìÔ∏è Correction des notes quotidiennes de la semaine\n")

    for date in dates:
        note_path = f"Daily/{date}.md"

        result = corrector.correct_note(note_path, create_backup=True)

        if result["success"]:
            if result.get("changes"):
                print(f"‚úÖ {date}: Corrig√©e")
            else:
                print(f"‚ûñ {date}: D√©j√† correcte")
        else:
            print(f"‚ùå {date}: {result.get('error', 'Non trouv√©e')}")

    print("\n‚ú® Correction termin√©e!")

if __name__ == "__main__":
    correct_daily_notes()
```

**Automatiser avec cron (macOS/Linux):**

```bash
# √âditer crontab
crontab -e

# Ajouter cette ligne (tous les jours √† 20h)
0 20 * * * cd ~/obsidian-multiagent && source venv/bin/activate && python daily_correction.py >> logs/daily.log 2>&1

# Explication:
# 0 20 * * *  ‚Üí minute=0, heure=20, tous les jours
# cd ~/obsidian-multiagent  ‚Üí se placer dans le dossier
# source venv/bin/activate  ‚Üí activer l'environnement
# python daily_correction.py  ‚Üí lancer le script
# >> logs/daily.log  ‚Üí rediriger stdout vers log
# 2>&1  ‚Üí rediriger stderr aussi vers log
```

### Script: Correction avant push Git

```python
#!/usr/bin/env python3
"""
pre_commit_correction.py - Corrige les notes modifi√©es avant commit
"""
import subprocess
from correct_spelling import SpellingCorrector
import os
from dotenv import load_dotenv

def get_modified_notes():
    """Obtient les notes .md modifi√©es depuis le dernier commit."""

    # Ex√©cuter git diff
    result = subprocess.run(
        ['git', 'diff', '--name-only', '--cached'],
        capture_output=True,
        text=True
    )

    # Filtrer les fichiers .md
    files = result.stdout.strip().split('\n')
    md_files = [f for f in files if f.endswith('.md')]

    return md_files

def main():
    load_dotenv()
    vault_path = os.getenv("OBSIDIAN_VAULT_PATH")

    # Obtenir notes modifi√©es
    modified = get_modified_notes()

    if not modified:
        print("Aucune note modifi√©e")
        return

    print(f"üìù {len(modified)} note(s) modifi√©e(s)\n")

    corrector = SpellingCorrector(vault_path)

    for note in modified:
        print(f"Correction de {note}...")
        result = corrector.correct_note(note, create_backup=False)

        if result["success"] and result.get("changes"):
            # Re-stager le fichier corrig√©
            subprocess.run(['git', 'add', note])
            print(f"  ‚úÖ Corrig√©e et re-staged")
        else:
            print(f"  ‚ûñ Aucune correction")

    print("\n‚ú® Pr√™t √† commit!")

if __name__ == "__main__":
    main()
```

**Installer comme git hook:**

```bash
# Copier dans .git/hooks/pre-commit
cp pre_commit_correction.py .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit

# Maintenant, √† chaque git commit, vos notes seront auto-corrig√©es!
```

---

## Debugging et troubleshooting

### Probl√®me: Le correcteur change trop de choses

**Solution: Augmenter la temp√©rature**

```python
# Dans correct_spelling.py
self.llm = Ollama(
    model=model,
    temperature=0.01,  # Ultra bas = ultra conservateur
)
```

**Ou: Prompt plus strict**

```python
prompt = f"""R√àGLE ABSOLUE: Change UNIQUEMENT ce qui est CLAIREMENT une faute.
En cas de doute, NE CHANGE RIEN.

Exemples de ce qui doit √™tre chang√©:
- "jai" ‚Üí "j'ai" (apostrophe manquante)
- "aujourdhui" ‚Üí "aujourd'hui" (orthographe)

Exemples de ce qui NE doit PAS √™tre chang√©:
- "email" (pas "e-mail", les deux sont corrects)
- "Okay" (variante acceptable de "OK")
- Style personnel

TEXTE: {text}
CORRIG√â:"""
```

### Probl√®me: Le correcteur est trop lent

**Diagnostic:**

```python
import time

start = time.time()
corrected = self.correct_text(text)
duration = time.time() - start

print(f"Temps: {duration:.2f}s")
```

**Solutions:**

1. **Utiliser un mod√®le plus petit**
   ```python
   corrector = SpellingCorrector(vault_path, model="mistral:7b")
   # Plus rapide mais peut-√™tre moins pr√©cis
   ```

2. **R√©duire la longueur du prompt**
   ```python
   # Au lieu d'un long prompt avec r√®gles...
   prompt = f"Corrige l'orthographe:\n{text}\nCorrig√©:"
   # Moins de tokens = plus rapide
   ```

3. **Limiter num_predict**
   ```python
   self.llm = Ollama(
       model=model,
       num_predict=512,  # Au lieu de 1024
   )
   # Moins de tokens √† g√©n√©rer = plus rapide
   ```

### Probl√®me: Erreur "Connection refused" avec Ollama

**Diagnostic:**

```python
import requests

try:
    r = requests.get("http://localhost:11434/api/version")
    print(f"Ollama r√©pond: {r.json()}")
except requests.exceptions.ConnectionError:
    print("Ollama ne r√©pond pas!")
```

**Solutions:**

```bash
# 1. V√©rifier si Ollama tourne
ps aux | grep ollama

# 2. Lancer Ollama
ollama serve

# 3. V√©rifier le port
lsof -i :11434  # Doit montrer ollama
```

### Probl√®me: Le backup prend trop de place

**Solution: Nettoyer les vieux backups**

```python
# cleanup_backups.py
from pathlib import Path
from datetime import datetime, timedelta
import os

def cleanup_old_backups(vault_path: str, days: int = 30):
    """Supprime les backups de plus de X jours."""

    backup_dir = Path(vault_path) / ".backups"

    if not backup_dir.exists():
        return

    cutoff = datetime.now() - timedelta(days=days)
    deleted = 0

    for backup_file in backup_dir.glob("*.md"):
        # Obtenir date de modification
        mtime = datetime.fromtimestamp(backup_file.stat().st_mtime)

        if mtime < cutoff:
            backup_file.unlink()  # Supprimer
            deleted += 1

    print(f"üóëÔ∏è {deleted} backups supprim√©s (>{days} jours)")

# Utilisation
cleanup_old_backups("/vault", days=30)
```

**Automatiser le nettoyage:**

```bash
# Dans crontab (tous les lundis √† 3h du matin)
0 3 * * 1 cd ~/obsidian-multiagent && source venv/bin/activate && python cleanup_backups.py
```

### Probl√®me: Le correcteur plante sur de grosses notes

**Diagnostic:**

```python
def correct_note(self, note_path: str):
    full_path = self.vault_path / note_path

    # V√©rifier la taille
    size = full_path.stat().st_size
    print(f"Taille: {size} bytes ({size/1024:.1f} KB)")

    if size > 100_000:  # 100 KB
        print("‚ö†Ô∏è Note tr√®s grande, risque de timeout")
```

**Solution: D√©couper en chunks**

```python
def correct_large_note(self, note_path: str, chunk_size: int = 10000):
    """Corrige une grande note par morceaux."""

    # Lire
    content = full_path.read_text()

    # D√©couper en paragraphes
    paragraphs = content.split('\n\n')

    corrected_paragraphs = []
    current_chunk = []
    current_size = 0

    for para in paragraphs:
        current_chunk.append(para)
        current_size += len(para)

        # Si chunk assez gros, corriger
        if current_size > chunk_size:
            chunk_text = '\n\n'.join(current_chunk)
            corrected = self.correct_text(chunk_text)
            corrected_paragraphs.append(corrected)

            # Reset
            current_chunk = []
            current_size = 0

    # Dernier chunk
    if current_chunk:
        chunk_text = '\n\n'.join(current_chunk)
        corrected = self.correct_text(chunk_text)
        corrected_paragraphs.append(corrected)

    # Recombiner
    return '\n\n'.join(corrected_paragraphs)
```

---

## R√©sum√© des patterns courants

### Pattern: Lecture s√©curis√©e

```python
def safe_read(file_path):
    """Lit un fichier avec gestion d'erreur."""
    try:
        return file_path.read_text(encoding='utf-8')
    except FileNotFoundError:
        return None
    except UnicodeDecodeError:
        # Fichier binaire ou mauvais encodage
        return None
    except Exception as e:
        print(f"Erreur: {e}")
        return None
```

### Pattern: Op√©ration avec rollback

```python
def safe_operation(file_path, operation_func):
    """Ex√©cute une op√©ration avec backup et rollback."""

    # Backup
    backup = create_backup(file_path)

    try:
        # Op√©ration
        operation_func(file_path)
        return {"success": True}

    except Exception as e:
        # Rollback
        if backup.exists():
            shutil.copy2(backup, file_path)
        return {"success": False, "error": str(e)}
```

### Pattern: Batch processing avec statistiques

```python
def process_batch(items, process_func):
    """Traite une liste d'items avec stats."""

    stats = {"total": len(items), "success": 0, "errors": 0}

    for i, item in enumerate(items, 1):
        print(f"[{i}/{len(items)}] Processing {item}...")

        try:
            process_func(item)
            stats["success"] += 1
        except Exception as e:
            stats["errors"] += 1
            print(f"  Error: {e}")

    return stats
```

---

Voil√†! Vous avez maintenant une compr√©hension compl√®te et pratique du fonctionnement du syst√®me. N'h√©sitez pas si vous avez des questions sur un aspect sp√©cifique!
